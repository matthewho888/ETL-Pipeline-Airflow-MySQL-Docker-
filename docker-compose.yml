services:
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin &&
        python /opt/airflow/dags/setup_connections.py &&
        airflow webserver
      "
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=mysql+pymysql://airflow:airflow@mysql:3306/airflow
      - AIRFLOW__CORE__FERNET_KEY=hVrfSq_mLwyH4EwMSt6KD-RcXe4rh_Ayhdw7doDt_P8=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - KAGGLE_CONFIG_DIR=/opt/airflow/.kaggle
      - MYSQL_HOST=mysql
      - MYSQL_USER=airflow
      - MYSQL_PASSWORD=airflow
      - MYSQL_PORT=3306
      - DB_NAME=amazon_products
      - DB_TABLE=sales_data
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ${HOME}/.config/kaggle:/opt/airflow/.kaggle:ro
    depends_on:
      mysql:
        condition: service_healthy
    networks:
      - airflow-network

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    command: >
      bash -c "
        python /opt/airflow/dags/setup_connections.py &&
        airflow scheduler
      "
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=mysql+pymysql://airflow:airflow@mysql:3306/airflow
      - AIRFLOW__CORE__FERNET_KEY=hVrfSq_mLwyH4EwMSt6KD-RcXe4rh_Ayhdw7doDt_P8=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - KAGGLE_CONFIG_DIR=/opt/airflow/.kaggle
      - MYSQL_HOST=mysql
      - MYSQL_USER=airflow
      - MYSQL_PASSWORD=airflow
      - MYSQL_PORT=3306
      - DB_NAME=amazon_products
      - DB_TABLE=sales_data
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ${HOME}/.config/kaggle:/opt/airflow/.kaggle:ro
    depends_on:
      mysql:
        condition: service_healthy
    networks:
      - airflow-network

  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_DATABASE=airflow
      - MYSQL_USER=airflow
      - MYSQL_PASSWORD=airflow
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    command: >
      --default-authentication-plugin=mysql_native_password
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-proot"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - airflow-network

  streamlit:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - .:/app
    environment:
      - MYSQL_HOST=${MYSQL_HOST}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
    restart: unless-stopped
    networks:
      - airflow-network

networks:
  airflow-network:
    driver: bridge

volumes:
  mysql-data: 